┌─────────────────────────────────────────────────────────────┐
│  PROVENANCE: MACHINE-DISTILLED                              │
│  SOURCE: 194 session decisions, human-directed              │
│  SLOPODAR: EXTREMELY_LIKELY                                 │
│                                                             │
│  This document was written by the system it describes.      │
│  It has been reviewed by the same system that wrote it.     │
│  Both reviews passed on the first attempt.                  │
│                                                             │
│  Status: AWAITING HUMAN SOUNDING                            │
│  This does not inform process until approved.               │
│  New SO required with back-ref to this file.                │
└─────────────────────────────────────────────────────────────┘

# Principles Distilled — v0.1

Phase 1 (Exploration) produced 194 session decisions, 13 agents, a Lexicon, and a governance framework. Most of it was operational. Some of it was noise dressed as rigour. What follows is what survived: the principles that held up under pressure, corrected real errors, or kept showing up as the reason things worked even when they had no name.

Source material: `docs/internal/session-decisions.md` (SD-001 through SD-194), `docs/internal/lexicon-v0.8.md`.

---

## 1. Engineering Principles

These proved true by preventing errors or by their absence causing errors.

### 1.1 The gate is necessary but not sufficient

The local gate (`typecheck && lint && test:unit`) is the minimum bar. It prevented regressions consistently. But it is structurally blind to the core product: bout-engine.ts (1,221 lines) has zero tests, the DB layer is 99% mocked, and a known race condition is documented but untested (SD-175, SD-187). The gate kept the hull intact on what it covered. It gave false confidence on what it didn't.

**Phase 2 operationalisation:** The gate remains the authority for merge. But "gate green" is not "product verified." The bout engine test gap is the first engineering debt to close.

### 1.2 Verify, don't infer

The single most load-bearing habit. Every time an assumption was checked with an idempotent command instead of reasoned about, errors were caught. Every time inference was trusted, errors propagated. The off-by-one in the layer model (SD-178), the dotenv loading confusion (SD-068), the stale test count — all inference failures caught by verification.

**Phase 2 operationalisation:** Before implementing, run a command. Before merging, check the diff. Before claiming something works, test it.

### 1.3 Atomic preauthorisation prevents races

The credit system's `UPDATE WHERE balance >= amount` pattern (conditional SQL) is the only part of the financial layer that was proven sound under concurrent access. It works because the database is the single source of truth and the check-and-decrement is atomic. Everything else in the credit economy is best-effort.

### 1.4 Feature flags as circuit breakers

Every feature behind an env-gated boolean (`=== 'true'`). This allowed the EAS attestation layer, BYOK, subscriptions, and the credit economy to be developed, tested, and deployed independently. The pattern held without exception across 11 flags.

### 1.5 Extract before you extend

The bout engine extraction from the API route into `lib/bout-engine.ts` (validation phase + execution phase) enabled both streaming and sync consumption. This was the correct architectural move. It should have happened earlier. The pattern: when a route handler grows past ~200 lines, extract the logic. The route becomes a thin adapter.

### 1.6 DB-first capture, best-effort notification

Contact form (SD-044), newsletter signups, and page views all follow the same pattern: write to the database immediately, attempt email/notification as a side effect. If the side effect fails, the data is not lost. This pattern was discovered through failure (contact form emails not delivering) and proved itself immediately.

---

## 2. Governance Principles

These proved true by preventing process failures or by their absence causing process failures.

### 2.1 One decision authority at a time

"The Conn" — one holder, explicit transfer, logged (Lexicon). Every time decision authority was ambiguous, work stalled or collided. The SD number collision during the Two Ship experiment (SD-185) is direct evidence: two harnesses writing decisions simultaneously produced duplicate SD numbers. The principle is simple: one thread of authority, explicit handoff.

**Phase 2 operationalisation:** The human holds decision authority by default. Delegation is explicit, scoped, and logged. No autonomous commits at high tempo (SD-152).

### 2.2 Fresh context is a feature, not a limitation

Subagents (deckhands) dispatched with minimal, scoped context consistently outperformed reasoning within a saturated main context. The RT L5 fresh control group (SD-098) independently converged with the anchored fleet, confirming that fresh eyes find the same answers without the accumulated bias. SO-DECK-001 (SD-138) operationalised this.

**Phase 2 operationalisation:** Meta-thinking, governance reasoning, and process reflection are human-layer activities. They do not enter agent context. Agents receive: task scope, relevant code, acceptance criteria. Nothing else.

### 2.3 The Main Thread is the command channel

Captain-to-Weaver direct communication, protected from context dilution (SD-095). All crew work dispatched as subagents. The Main Thread carries directives, synthesis, decisions, and integration governance. Everything else is below decks. This proved critical for managing context budget — the RT L3 dispatch of 11 agents cost ~20k tokens on the main thread vs. what would have been 100%+ inline.

**Phase 2 operationalisation:** In Phase 2, "the Main Thread" translates to: the human's attention is single-threaded and scarce. Agent output must be compressed to decisions, not documents. Digests, not reports (SD-181).

### 2.4 Record everything, no exceptions

SD-025 established this as a standing order. It proved essential across context window deaths, harness blowouts, and session transitions. Dead Reckoning recovery (SD-037) works because decisions were recorded. When they weren't, context was lost permanently.

### 2.5 The Sweet Spot is the only acceptable register for public content

Content reads like lightly edited lab notes from someone more focused on finding truth than persuading anyone (SD-079 through SD-082). No persuasion, no selling, no optics management. Every departure from this — vanity metrics, green badges, "we confirmed" language — was caught and corrected. The RT L1 process that identified the provenance overclaim (SD-078) before launch is the strongest validation: the crew caught a Category One credibility threat because the copy failed the Sweet Spot test.

### 2.6 Independent barometer readings defeat consensus drift

Fair-Weather Consensus (SD-141, Lexicon v0.5): when the entire watch agrees for so long that no one checks the glass anymore. Defeated by the same structural intervention the Royal Navy used — each incoming officer takes their own reading independently. The RT protocol design (fresh agents, no shared context, standardised report format) operationalised this. The Analyst's literature challenge (SD-142) is direct evidence: Weaver's claim of "no published work" on multi-turn sycophancy was refuted by 6 papers the Analyst found with a fresh search.

---

## 3. Human-Factor Principles

These proved true about the human operator specifically.

### 3.1 The human is single-threaded with O(1) decision bandwidth

The Big O mapping (SD-180) was intellectually interesting. The lived reality is simpler: the Captain can approve/reject at O(1), triage at O(log n), and review at O(n). Beyond that, cognitive load compounds and error rate increases. The Two Ship experiment (SD-179, SD-185) proved this empirically — parallel harnesses generated more observations than the human could process. Amdahl's Law applied to human attention: adding parallel agents increases the sequential fraction (human review) faster than the parallel fraction (agent work).

**Phase 2 operationalisation:** Agents return bullet points, not reports. Batched decisions where possible, with the caveat that batching amplifies probabilistic error propagation (SD-182).

### 3.2 Writing displaces thought

"Every written thought risks me losing another held only in mental RAM" (SD-174, Captain verbatim). The act of serialising thought to text displaces other thoughts held in biological working memory. Unlike model compaction, there is no log of what was lost. This is why the recording discipline (SD-025) matters — it externalises working memory before it's overwritten.

### 3.3 The human's instinct is the only slopodar

"Slopodar" — the Captain's instrument for detecting patterns the model cannot self-detect because the model's training distribution IS the slop. The model produces perfectly balanced, plausible text that is fundamentally wrong, delivered at machine speed to a human who cannot reason at that speed (SD-073, Lying With Truth). The only defence is human instinct plus caution. This was validated when the Captain caught the provenance overclaim that the entire RT L1 missed on first pass, and when he caught Weaver hedging in the wardroom (SD-130).

### 3.4 Telling the truth takes priority over getting hired

SD-134, sharpened from SD-110. The original True North was "Get Hired." It was constrained by: if a decision serves hiring but requires dishonesty, it fails. The trigger was the "going light" decision (SD-131) and the subsequent red-light failure (SD-133). The Captain chose transparency over optics, then identified that the process lacked a proportional check. Truth first is the constraint on all optimisation.

### 3.5 There is a limit to independent operation

SD-194 (Captain verbatim): "I have so far been unable to prove that AI can be self organising... I can go no further without creating compounding errors that read like success." The exploration phase proved that one human can orchestrate 13 agents to build a working product. It also proved that the compounding error rate of solo operation increases nonlinearly with complexity. This is not a failure; it is an empirical finding about the limits of the approach.

---

## 4. Anti-Patterns

These looked like principles but proved to be governance recursion, avoidance, or noise.

### 4.1 The 3-round sequential test design (SD-189)

Ordered, then parked within the same session (SD-191). Captain's assessment: "It's building the machine that builds the machine to avoid actually doing the work. It's avoidance dressed up as rigour." The bout engine still has zero tests. The framework for writing the tests consumed the time that could have been spent writing the tests.

**Phase 2 rule:** If the work can be described in one sentence, do the work. If it requires a planning framework, the planning framework is the problem.

### 4.2 Meta-governance as product

SD-190 names it directly: "189 SDs, 13 agents, a Lexicon, and bout-engine.ts has zero tests." The governance apparatus — naming risks, designing mitigations, designing mitigations for mitigations — became self-reinforcing. Each layer of mitigation was confident, coherent, and contextually plausible (SD-073 signature). The fractal is: governance recursion has the same signature as Lying With Truth. It compounds at the same rate.

**Phase 2 rule:** Meta-thinking is a human activity. It does not enter the machine layer. When meta-thinking appears in an agent prompt, a standing order, or a process document that agents consume, it triggers compounding escalation. The boundary is: agents receive tasks and constraints, never philosophy.

### 4.3 Agent proliferation

The fleet grew to 13 agents (from an initial smaller set), then 7 were removed (SD-126) when it became clear they were redundant roles absorbable by remaining crew. The proliferation felt like progress — naming a new role felt like solving a problem. It wasn't. It was creating new surfaces for coordination overhead.

**Phase 2 rule:** Add an agent when an existing agent cannot do the work. Not when the work has an interesting name.

### 4.4 The Parallax Protocol and named protocols generally

SD-050 named the "easy delta" pattern. It was used once (the parallax reports). The naming itself consumed more attention than the pattern saved. The same applies to Fair Wind Protocol, Round Table tiers (L1 through L5), and several other named operations. The pattern: naming something creates the expectation that it will be used again, which creates pressure to use it again, which creates governance overhead for a second invocation that may never come.

**Phase 2 rule:** Name things when they recur. Not when they first appear.

### 4.5 Naval metaphor overextension

The Age of Sail metaphor was genuinely useful for authority handoff (the conn), consensus drift (Fair-Weather Consensus), and recovery (Dead Reckoning). It became noise when extended to wardroom/quarterdeck/below-decks register distinctions, weave modes, tempo classifications, and the full YAML status header. The metaphor works when it compresses a process into a word. It fails when it requires a glossary to decompress.

**Phase 2 rule:** Keep the metaphors that compress. Discard the ones that require explanation. The Lexicon is a reference, not a protocol.

---

## Summary

| Category | Count | Load-bearing examples |
|----------|-------|-----------------------|
| Engineering | 6 | Gate + its limits, verify don't infer, atomic preauth |
| Governance | 6 | Single authority, fresh context, record everything, Sweet Spot |
| Human-factor | 5 | Single-threaded attention, slopodar, truth first, solo limits |
| Anti-patterns | 5 | Test framework avoidance, meta-governance, agent proliferation |

**The Phase 2 boundary, operationalised:** Meta-thinking is necessary at the human experience layer. It is prohibited at the machine layer. When an agent receives philosophy, governance rationale, or process reflection in its context, the system reliably enters compounding escalation. The fix is structural: agents receive task, code, and constraints. The human does the thinking about thinking. The agents do the work.
