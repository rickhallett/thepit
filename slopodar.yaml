# slopodar.yaml — Anti-patterns of LLM authenticity
#
# A living inventory of tells, tics, and tendencies that make LLM output
# sound like LLM output. Each entry is a pattern to watch for and ward off.
#
# Named after the radar that detects slop before it reaches production.
# Maintained by the Captain and crew. Entries are added when caught
# in the wild.
#
# This file is the single source of truth for the oceanheart Hugo site's
# /slopodar/ section. The Makefile sync target copies it into
# sites/oceanheart/data/slopodar.yaml and generates content stubs from it.
# Do not move or rename without updating sites/oceanheart/Makefile.
#
# Format:
#   - id: short kebab-case identifier
#     name: human-readable name
#     detected: date first caught
#     trigger: the specific text or pattern that surfaced this
#     description: what the pattern is and why it's a problem
#     signal: what it communicates to a discerning reader
#     instead: what a human would actually write
#     severity: low | medium | high
#     refs: where it was caught (SD number, file, context)

patterns:

  - id: tally-voice
    name: "Tally Voice"
    detected: 2026-02-27
    trigger: "15 systems mapped to 7 literature domains"
    description: >
      The LLM substitutes enumeration for substance. Precise counts
      deployed as rhetorical authority — "6 constructs," "15 systems,"
      "7 domains" — when the numbers add nothing. The count performs
      rigor without demonstrating it. A human who found genuine
      connections between their work and the literature would talk
      about the connections, not inventory them.
    signal: >
      To a discerning reader (HN, hiring manager, researcher): this
      person didn't write this. A human says "the governance systems
      keep turning up in distributed cognition research." An LLM says
      "15 engineering systems mapped to 7 literature domains."
    instead: >
      "The engineering work maps onto distributed cognition research
      in ways I didn't expect." Let the table speak for itself.
      The reader can count.
    severity: high
    refs:
      - "SD-209 (oceanheart.ai overhaul)"
      - "sites/oceanheart/content/research/prospective-regulation.md"
      - "sites/oceanheart/content/research/metacognitive-analysis.md"

  - id: redundant-antithesis
    name: "Redundant Antithesis"
    detected: 2026-02-27
    trigger: "caught in the wild — not theorised in advance"
    description: >
      Negative-positive antithesis where the negation adds zero
      information. The classical form ("not A, but B") is a deliberate
      rhetorical choice — Aristotle documented it. The LLM form is
      an RLHF-trained reflex: contrastive structures score higher in
      preference rankings, so the model generates them compulsively.
      "Caught in the wild" already implies "not theorised." The
      negation is dead weight that makes the sentence sound like a
      TED talk.
    signal: >
      Pre-LLM, this was a stylistic choice with real rhetorical force.
      Post-LLM, everyone uses AI as their copyeditor and this
      construction is everywhere. A discerning reader now pattern-matches
      it as AI-generated prose. The structure that once signalled
      decisiveness now signals "a model wrote this."
    instead: >
      Just say the positive. "Entries are added when caught in the
      wild." The reader does not need to be told what the alternative
      was. If the contrast genuinely adds meaning, keep it. If the
      reader already knows the negated term, cut it.
    severity: high
    refs:
      - "SD-209 (slopodar.yaml header comment)"
      - "sites/oceanheart/layouts/_default/slopodar.html (page description)"

  - id: epistemic-theatre
    name: "Epistemic Theatre"
    detected: 2026-02-27
    trigger: '"The uncomfortable truth" / "The Problem Nobody Talks About" / "Here''s why this matters"'
    description: >
      The model performs intellectual seriousness instead of being
      intellectually serious. Theatrical framing that signals
      significance, candor, or novelty without delivering any.
      Three sub-patterns: False Candor ("the uncomfortable truth" —
      performs bravery, signals "I'm about to be honest," which is
      what you say when you usually aren't); False Novelty ("the
      problem nobody talks about" — performs discovery, implies
      exclusive insight, almost always followed by something many
      people talk about); Significance Signpost ("here's why this
      matters" — tells the reader the preceding content was important,
      which it either was and the sign is redundant, or wasn't and
      the sign can't save it).
    signal: >
      Slop-101. These are the first patterns a discerning reader
      learns to detect. They're the constructions that make someone
      stop reading and think "a model wrote this." A hostile HN
      commenter would screenshot any of these. Pre-LLM, some of
      these had rhetorical force in specific contexts. Post-LLM,
      they are burned beyond recovery.
    instead: >
      Delete the line. The content either carries the weight or it
      doesn't. "The uncomfortable truth" becomes nothing — just
      state the truth. "The problem nobody talks about" becomes
      nothing — just describe the problem. "Here's why this matters"
      becomes nothing — if you showed it well, the reader already
      knows.
    severity: high
    refs:
      - "Blog sweep 2026-02-27 (poker-incident.md, prompt-injection.md)"
      - "Reviewer feedback on epistemic theatre in blog content"

  - id: becoming-jonah
    name: "Becoming Jonah"
    detected: 2026-02-27
    trigger: "a blog post about how your blog posts sound, scored with an XML rubric"
    category: TBD
    description: >
      Recursive metacognition with an LLM. You reflect on your output.
      Then you reflect on your reflections. Then you build a rubric to
      score the reflections. Then you write about the rubric. You are
      inside the whale, examining the whale. The recursion is seductive
      because each level feels like genuine insight — and sometimes it
      is. The problem is not the recursion itself but publishing it
      before you have a body of work that demonstrates what the
      recursion produced. Methodology before artifact. The map before
      the territory exists.
    signal: >
      To an external reader: process without product. To a hiring
      manager: "this person thinks about thinking about thinking but
      what did they ship?" To yourself: potentially valuable as a
      private learning tool — exploring a new problem space in your
      mother tongue. The danger is mistaking the exploration for the
      destination. Not all Jonahs need an audience.
    instead: >
      Keep the rubric. Use the rubric. Publish the work the rubric
      produces. If the rubric is genuinely novel, publish it after
      the body of work proves it works — the slopodar is the model
      here: patterns caught in the wild, not theorised in advance.
      The voice rubric becomes infrastructure, not content.
    severity: medium
    refs:
      - "2026-02-19-voice-rubric.md (moved to docs/internal/archive/ice/)"
      - "Category TBD — Captain flagged as needing its own new category"
